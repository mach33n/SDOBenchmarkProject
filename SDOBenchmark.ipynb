{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c05422",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561b461-68c8-4779-a83f-eb1cb4520560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67de96-b138-41df-9fcd-3b60cc127536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"))) + \" Images for sample 1\")\n",
    "print(str(len(glob.glob(\"./training/*/*\"))) + \" Different Samples\")\n",
    "# Avg number of images per sample\n",
    "print(str(len(glob.glob(\"./training/*/*/*\"))/len(glob.glob(\"./training/*/*\"))) + \" Average number images per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fec3f7-97c8-4d2f-addd-4ab18bd1416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for a single sample\n",
    "sample = []\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"):\n",
    "    print(i)\n",
    "    sample.append(Image.open(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89362f22-8024-4b72-905b-ab31e705f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_continuum.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad49a96-3df1-4a8e-ac90-158050fdf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_magnetogram.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67364843-2499-4858-9ddd-2931839f2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_211.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca01c0c-cf05-46ed-81ae-157774939034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _# represents AIA wavelength for band #\n",
    "# Hour Times: 05, 12, 15, 16\n",
    "# Not sure what continuum images represent\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_304.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654af0e-8183-4087-9e7f-88e81e75e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e767e5e-cf76-45fc-98e5-9661ebbcf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sample[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c509a15-d5f5-4293-81c1-d1e4085faaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"./training/11390/2012_01_05_17_06_01_0/2012-01-05T153601__magnetogram.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc65d-4e28-4e75-8245-fcbd36720f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.format)\n",
    "print(img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e766d-c02a-4180-ab74-deb3930fbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8d027-3c19-4163-91ad-f298267a34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8E-07 is peak flux for this sample\n",
    "# Data Transformation 1: \n",
    "i = img.split()[0]\n",
    "len(i.histogram())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349bbea9",
   "metadata": {},
   "source": [
    "## Baseline network\n",
    "This network should directly predict peak flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad1415-ba73-4bd6-b2f7-db7242cbe986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(10, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 256 * 256 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Model\n",
    "This model predicts temperature and then converts at the end to flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNWithWien(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNNWithWien, self).__init__()\n",
    "        # Adjusted convolutional layers for 3D data\n",
    "        self.conv1 = nn.Conv3d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "\n",
    "        # Adjusted pooling layers\n",
    "        self.pool3d = nn.MaxPool3d(2, 2)\n",
    "        \n",
    "        # Linear layers\n",
    "        # Update the input features of fc1 according to the output size of the last pooling layer\n",
    "        # Example dimensions: 64 * 32 * 32 * 1 = 65536, if the final output size is [64, 32, 32, 1]\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 512)  # Adjust these dimensions\n",
    "        self.fc2 = nn.Linear(512, 1)  # Outputting temperature\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Wien's displacement constant (meters * Kelvin)\n",
    "        self.wien_constant = 2.897771955e-3\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool3d(F.relu(self.conv1(x)))\n",
    "        x = self.pool3d(F.relu(self.conv2(x)))\n",
    "        x = self.pool3d(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten image input\n",
    "        x = x.view(-1, 64 * 32 * 32)  # Update these dimensions accordingly\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 2nd hidden layer (outputs temperature)\n",
    "        temperature = self.fc2(x)\n",
    "\n",
    "        # Apply Wien's equation to calculate peak wavelength\n",
    "        # Prevent division by zero in case temperature is zero\n",
    "        temperature = torch.clamp(temperature, min=1e-6)\n",
    "        peak_wavelength = self.wien_constant / temperature\n",
    "\n",
    "        return peak_wavelength\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4e96b",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "A single input will be a 4x256x256x10 matrix where dimensions represent: [timeinterval x height x width x wavelength/magnetogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314188a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Get a list of all active region numbers\n",
    "all_files = glob.glob(\"./training/*/*\")\n",
    "\n",
    "# Split all_files into 10 chunks\n",
    "chunks = np.array_split(all_files, 40)\n",
    "print(len(chunks[0]))\n",
    "\n",
    "def generateChunk(idxs):\n",
    "    wavelengths = [\"94\",\"131\", \"171\",\"193\",\"211\",\"304\",\"335\",\"1700\",\"continuum\",\"magnetogram\"]\n",
    "    x = np.zeros((len(idxs), 4, 256, 256, 10), dtype=np.int64)\n",
    "    y = np.zeros((len(idxs), 1), dtype=np.int64)  # Updated data type to int64\n",
    "    df = pd.read_csv('training/meta_data.csv')\n",
    "    peak_flux_dict = {idx: peak_flux for idx, peak_flux in zip(df['id'], df['peak_flux'])}\n",
    "\n",
    "    for i, sample in enumerate(idxs):\n",
    "        images = np.empty((4, 256, 256, 10), dtype=np.int64)\n",
    "        for j, wave in enumerate(wavelengths):\n",
    "            path = sample + \"/*_{}.jpg\".format(wave)\n",
    "            pics = np.array([np.array(Image.open(i)) for i in glob.glob(path)])\n",
    "            for _ in range(4 - len(pics)):\n",
    "                if len(pics) == 0:\n",
    "                    pics = np.zeros((1, 256, 256))\n",
    "                else:\n",
    "                    pics = np.concatenate((pics, np.zeros((1, 256, 256))), axis=0)\n",
    "            pics = pics.reshape(4, 256, 256, 1)\n",
    "            images[:, :, :, j] = pics[:, :, :, 0]\n",
    "        images = images[:, :, :, :]\n",
    "        x[i] = images\n",
    "\n",
    "        idx = path.split(\"/\")[2] + \"_\"+ path.split(\"/\")[3]\n",
    "        peak_flux = peak_flux_dict[idx]\n",
    "\n",
    "        if peak_flux < 1e-5:\n",
    "            y[i] = 0  # Common\n",
    "        elif peak_flux < 1e-4:\n",
    "            y[i] = 1  # Moderate\n",
    "        else:\n",
    "            y[i] = 2  # Extreme\n",
    "\n",
    "    return torch.from_numpy(x.transpose(0,4,2,3,1)), torch.from_numpy(y)\n",
    "\n",
    "#for i in range(40):\n",
    "#    train_x, train_y = generateChunk(chunks[i])\n",
    "#    dataset = TensorDataset(train_x, train_y)\n",
    "#    torch.save(dataset, \"datachunks/chunk_{}.pt\".format(i))\n",
    "\n",
    "## Create a DataLoader\n",
    "#val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "def train_model(model, criterion, optimizer, epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move the model to the GPU if available\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(39):\n",
    "            train_x, train_y = generateChunk(chunks[i])\n",
    "            dataset = TensorDataset(train_x, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            model.train()  # Set the model to training mode\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).long().reshape(-1)  # Move data to GPU\n",
    "                optimizer.zero_grad()  # Reset the gradients\n",
    "                outputs = model(inputs)  # Forward pass\n",
    "                loss = criterion(outputs, targets)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update weights\n",
    "\n",
    "        train_x, train_y = generateChunk(chunks[39])\n",
    "        dataset = TensorDataset(train_x, train_y)\n",
    "        val_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # No need to track gradients in validation phase\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "            total_samples = 0\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).long().reshape(-1)  # Move data to GPU\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss.item() * len(targets)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_correct += torch.sum(predicted == targets)\n",
    "                total_samples += len(targets)\n",
    "        \n",
    "        avg_loss = total_loss / total_samples\n",
    "        accuracy = total_correct / total_samples\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss}, Accuracy: {accuracy}')\n",
    "\n",
    "mod = SimpleCNN()\n",
    "train_model(mod, nn.CrossEntropyLoss(), torch.optim.Adam(mod.parameters()), 10)\n",
    "mod = SimpleCNNWithWien()\n",
    "train_model(mod, nn.CrossEntropyLoss(), torch.optim.Adam(mod.parameters()), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
