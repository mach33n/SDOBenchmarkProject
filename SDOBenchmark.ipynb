{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c05422",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3561b461-68c8-4779-a83f-eb1cb4520560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67de96-b138-41df-9fcd-3b60cc127536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"))) + \" Images for sample 1\")\n",
    "print(str(len(glob.glob(\"./training/*/*\"))) + \" Different Samples\")\n",
    "# Avg number of images per sample\n",
    "print(str(len(glob.glob(\"./training/*/*/*\"))/len(glob.glob(\"./training/*/*\"))) + \" Average number images per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fec3f7-97c8-4d2f-addd-4ab18bd1416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for a single sample\n",
    "sample = []\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"):\n",
    "    print(i)\n",
    "    sample.append(Image.open(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89362f22-8024-4b72-905b-ab31e705f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_continuum.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad49a96-3df1-4a8e-ac90-158050fdf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_magnetogram.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67364843-2499-4858-9ddd-2931839f2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_211.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca01c0c-cf05-46ed-81ae-157774939034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _# represents AIA wavelength for band #\n",
    "# Hour Times: 05, 12, 15, 16\n",
    "# Not sure what continuum images represent\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_304.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654af0e-8183-4087-9e7f-88e81e75e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e767e5e-cf76-45fc-98e5-9661ebbcf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sample[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c509a15-d5f5-4293-81c1-d1e4085faaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"./training/11390/2012_01_05_17_06_01_0/2012-01-05T153601__magnetogram.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc65d-4e28-4e75-8245-fcbd36720f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.format)\n",
    "print(img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e766d-c02a-4180-ab74-deb3930fbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8d027-3c19-4163-91ad-f298267a34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8E-07 is peak flux for this sample\n",
    "# Data Transformation 1: \n",
    "i = img.split()[0]\n",
    "len(i.histogram())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349bbea9",
   "metadata": {},
   "source": [
    "## Baseline network\n",
    "This network should directly predict peak flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ad1415-ba73-4bd6-b2f7-db7242cbe986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (pool3d): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=65536, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Adjusted convolutional layers for 3D data\n",
    "        self.conv1 = nn.Conv3d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "\n",
    "        # Adjusted pooling layers\n",
    "        self.pool3d = nn.MaxPool3d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 32 * 32 * 1, 512)\n",
    "        \n",
    "        # Rest of the network remains the same\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool3d(F.relu(self.conv1(x)))\n",
    "        x = self.pool3d(F.relu(self.conv2(x)))\n",
    "        x = self.pool3d(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten image input\n",
    "        x = x.view(-1, 64 * 32 * 32 * 1)  # Update these dimensions accordingly\n",
    "\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 2nd hidden layer for regression\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN for regression\n",
    "model = SimpleCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Model\n",
    "This model predicts temperature and then converts at the end to flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNWithWien(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNNWithWien, self).__init__()\n",
    "        # Adjusted convolutional layers for 3D data\n",
    "        self.conv1 = nn.Conv3d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "\n",
    "        # Adjusted pooling layers\n",
    "        self.pool3d = nn.MaxPool3d(2, 2)\n",
    "        \n",
    "        # Linear layers\n",
    "        # Update the input features of fc1 according to the output size of the last pooling layer\n",
    "        # Example dimensions: 64 * 32 * 32 * 1 = 65536, if the final output size is [64, 32, 32, 1]\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 512)  # Adjust these dimensions\n",
    "        self.fc2 = nn.Linear(512, 1)  # Outputting temperature\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Wien's displacement constant (meters * Kelvin)\n",
    "        self.wien_constant = 2.897771955e-3\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool3d(F.relu(self.conv1(x)))\n",
    "        x = self.pool3d(F.relu(self.conv2(x)))\n",
    "        x = self.pool3d(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten image input\n",
    "        x = x.view(-1, 64 * 32 * 32)  # Update these dimensions accordingly\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 2nd hidden layer (outputs temperature)\n",
    "        temperature = self.fc2(x)\n",
    "\n",
    "        # Apply Wien's equation to calculate peak wavelength\n",
    "        # Prevent division by zero in case temperature is zero\n",
    "        temperature = torch.clamp(temperature, min=1e-6)\n",
    "        peak_wavelength = self.wien_constant / temperature\n",
    "\n",
    "        return peak_wavelength\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4e96b",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "A single input will be a 4x256x256x10 matrix where dimensions represent: [timeinterval x height x width x wavelength/magnetogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314188a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Get a list of all active region numbers\n",
    "all_files = glob.glob(\"./training/*/*\")\n",
    "\n",
    "# Split all_files into 10 chunks\n",
    "chunks = np.array_split(all_files, 40)\n",
    "print(len(chunks[0]))\n",
    "\n",
    "def generateChunk(idxs):\n",
    "    wavelengths = [\"94\",\"131\", \"171\",\"193\",\"211\",\"304\",\"335\",\"1700\",\"continuum\",\"magnetogram\"]\n",
    "    x = torch.zeros((1,4,256,256,10))\n",
    "    y = torch.zeros((1,1))\n",
    "    df = pd.read_csv('training/meta_data.csv')\n",
    "\n",
    "    # First we will loop over every active region number\n",
    "    train_files = chunks[0]\n",
    "    for sample in tqdm(train_files):\n",
    "        images = torch.empty((4,256,256,1), dtype=torch.int64)\n",
    "        for wave in wavelengths:\n",
    "            path = sample + \"/*_{}.jpg\".format(wave)\n",
    "            pics = torch.tensor([np.array(Image.open(i)) for i in glob.glob(path)])\n",
    "            for _ in range(4 - len(pics)):\n",
    "                pics = torch.cat((pics, torch.zeros((1, 256,256))), 0)\n",
    "            pics = pics.reshape(4,256,256,1)\n",
    "            images = torch.cat((images, pics), 3)\n",
    "        images = images[:,:,:,1:]\n",
    "        images = images.reshape(1,4,256,256,10)\n",
    "        x = torch.cat((x, images), 0)\n",
    "        idx = path.split(\"/\")[2] + \"_\"+ path.split(\"/\")[3]\n",
    "        y = torch.cat((y, torch.tensor(df[df[\"id\"] == idx]['peak_flux'].iloc[0]).reshape(-1,1)), 0)\n",
    "    return x, y\n",
    "\n",
    "#for i in range(40):\n",
    "#    train_x, train_y = generateChunk(chunks[i])\n",
    "#    dataset = TensorDataset(train_x, train_y)\n",
    "#    torch.save(dataset, \"datachunks/chunk_{}.pt\".format(i))\n",
    "\n",
    "## Create a DataLoader\n",
    "#val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685d339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [02:42<00:00,  1.28it/s]\n",
      "  3%|▎         | 1/39 [05:00<3:10:04, 300.11s/it]"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for i in tqdm(range(39)):\n",
    "            train_x, train_y = generateChunk(chunks[i])\n",
    "            dataset = TensorDataset(train_x, train_y)\n",
    "            train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "            model.train()  # Set the model to training mode\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()  # Reset the gradients\n",
    "                outputs = model(inputs)  # Forward pass\n",
    "                loss = criterion(outputs, targets.float())  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update weights\n",
    "\n",
    "        train_x, train_y = generateChunk(chunks[39])\n",
    "        dataset = TensorDataset(train_x, train_y)\n",
    "        val_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # No need to track gradients in validation phase\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, acc: {torch.sum(outputs == targets) / len(targets)}')\n",
    "\n",
    "mod = SimpleCNN()\n",
    "train_model(mod, nn.MSELoss(), torch.optim.Adam(mod.parameters()), 10)\n",
    "mod = SimpleCNNWithWien()\n",
    "train_model(mod, nn.MSELoss(), torch.optim.Adam(mod.parameters()), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
