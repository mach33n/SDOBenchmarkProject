{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c05422",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3561b461-68c8-4779-a83f-eb1cb4520560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67de96-b138-41df-9fcd-3b60cc127536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"))) + \" Images for sample 1\")\n",
    "print(str(len(glob.glob(\"./training/*/*\"))) + \" Different Samples\")\n",
    "# Avg number of images per sample\n",
    "print(str(len(glob.glob(\"./training/*/*/*\"))/len(glob.glob(\"./training/*/*\"))) + \" Average number images per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fec3f7-97c8-4d2f-addd-4ab18bd1416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for a single sample\n",
    "sample = []\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"):\n",
    "    print(i)\n",
    "    sample.append(Image.open(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89362f22-8024-4b72-905b-ab31e705f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_continuum.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad49a96-3df1-4a8e-ac90-158050fdf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_magnetogram.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67364843-2499-4858-9ddd-2931839f2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_211.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca01c0c-cf05-46ed-81ae-157774939034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _# represents AIA wavelength for band #\n",
    "# Hour Times: 05, 12, 15, 16\n",
    "# Not sure what continuum images represent\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_304.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654af0e-8183-4087-9e7f-88e81e75e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e767e5e-cf76-45fc-98e5-9661ebbcf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sample[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c509a15-d5f5-4293-81c1-d1e4085faaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"./training/11390/2012_01_05_17_06_01_0/2012-01-05T153601__magnetogram.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc65d-4e28-4e75-8245-fcbd36720f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.format)\n",
    "print(img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e766d-c02a-4180-ab74-deb3930fbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8d027-3c19-4163-91ad-f298267a34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8E-07 is peak flux for this sample\n",
    "# Data Transformation 1: \n",
    "i = img.split()[0]\n",
    "len(i.histogram())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349bbea9",
   "metadata": {},
   "source": [
    "## Baseline network\n",
    "This network should directly predict peak flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99ad1415-ba73-4bd6-b2f7-db7242cbe986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv3d(4, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (pool3d): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=65536, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Adjusted convolutional layers for 3D data\n",
    "        self.conv1 = nn.Conv3d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "\n",
    "        # Adjusted pooling layers\n",
    "        self.pool3d = nn.MaxPool3d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 32 * 32 * 1, 512)\n",
    "        \n",
    "        # Rest of the network remains the same\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool3d(F.relu(self.conv1(x)))\n",
    "        x = self.pool3d(F.relu(self.conv2(x)))\n",
    "        x = self.pool3d(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten image input\n",
    "        x = x.view(-1, 64 * 32 * 32 * 1)  # Update these dimensions accordingly\n",
    "\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 2nd hidden layer for regression\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN for regression\n",
    "model = SimpleCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Model\n",
    "This model predicts temperature and then converts at the end to flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNWithWien(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNNWithWien, self).__init__()\n",
    "        # Adjusted convolutional layers for 3D data\n",
    "        self.conv1 = nn.Conv3d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 64, 3, padding=1)\n",
    "\n",
    "        # Adjusted pooling layers\n",
    "        self.pool3d = nn.MaxPool3d(2, 2)\n",
    "        \n",
    "        # Linear layers\n",
    "        # Update the input features of fc1 according to the output size of the last pooling layer\n",
    "        # Example dimensions: 64 * 32 * 32 * 1 = 65536, if the final output size is [64, 32, 32, 1]\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 512)  # Adjust these dimensions\n",
    "        self.fc2 = nn.Linear(512, 1)  # Outputting temperature\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # Wien's displacement constant (meters * Kelvin)\n",
    "        self.wien_constant = 2.897771955e-3\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool3d(F.relu(self.conv1(x)))\n",
    "        x = self.pool3d(F.relu(self.conv2(x)))\n",
    "        x = self.pool3d(F.relu(self.conv3(x)))\n",
    "\n",
    "        # Flatten image input\n",
    "        x = x.view(-1, 64 * 32 * 32)  # Update these dimensions accordingly\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Add 2nd hidden layer (outputs temperature)\n",
    "        temperature = self.fc2(x)\n",
    "\n",
    "        # Apply Wien's equation to calculate peak wavelength\n",
    "        # Prevent division by zero in case temperature is zero\n",
    "        temperature = torch.clamp(temperature, min=1e-6)\n",
    "        peak_wavelength = self.wien_constant / temperature\n",
    "\n",
    "        return peak_wavelength\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4e96b",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "A single input will be a 4x256x256x10 matrix where dimensions represent: [timeinterval x height x width x wavelength/magnetogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314188a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb Cell 20\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m TensorDataset, DataLoader\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Get a list of all active region numbers\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m all_files \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m./training/*/*\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NLP/lib/python3.11/site-packages/torch/utils/data/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TODO(VitalyFedyunin): Rearranging this imports leads to crash,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# need to cleanup dependencies and fix it\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msampler\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     BatchSampler,\n\u001b[1;32m      5\u001b[0m     RandomSampler,\n\u001b[1;32m      6\u001b[0m     Sampler,\n\u001b[1;32m      7\u001b[0m     SequentialSampler,\n\u001b[1;32m      8\u001b[0m     SubsetRandomSampler,\n\u001b[1;32m      9\u001b[0m     WeightedRandomSampler,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     ChainDataset,\n\u001b[1;32m     13\u001b[0m     ConcatDataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     random_split,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatapipe\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     DFIterDataPipe,\n\u001b[1;32m     22\u001b[0m     DataChunk,\n\u001b[1;32m     23\u001b[0m     IterDataPipe,\n\u001b[1;32m     24\u001b[0m     MapDataPipe,\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NLP/lib/python3.11/site-packages/torch/utils/data/sampler.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterator, Iterable, Optional, Sequence, List, TypeVar, Generic, Sized, Union\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NLP/lib/python3.11/site-packages/torch/__init__.py:249\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[1;32m    236\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    251\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Get a list of all active region numbers\n",
    "all_files = glob.glob(\"./training/*/*\")\n",
    "\n",
    "# Split all_files into 10 chunks\n",
    "chunks = np.array_split(all_files, 20)\n",
    "\n",
    "def generateChunk(idxs):\n",
    "    wavelengths = [\"94\",\"131\", \"171\",\"193\",\"211\",\"304\",\"335\",\"1700\",\"continuum\",\"magnetogram\"]\n",
    "    x = torch.zeros((1,4,256,256,10))\n",
    "    y = torch.zeros((1,1))\n",
    "    df = pd.read_csv('training/meta_data.csv')\n",
    "\n",
    "    # First we will loop over every active region number\n",
    "    train_files = chunks[0]\n",
    "    for sample in tqdm(train_files):\n",
    "        images = torch.empty((4,256,256,1), dtype=torch.int64)\n",
    "        for wave in wavelengths:\n",
    "            path = sample + \"/*_{}.jpg\".format(wave)\n",
    "            pics = torch.tensor([np.array(Image.open(i)) for i in glob.glob(path)])\n",
    "            for _ in range(4 - len(pics)):\n",
    "                pics = torch.cat((pics, torch.zeros((1, 256,256))), 0)\n",
    "            pics = pics.reshape(4,256,256,1)\n",
    "            images = torch.cat((images, pics), 3)\n",
    "        images = images[:,:,:,1:]\n",
    "        images = images.reshape(1,4,256,256,10)\n",
    "        x = torch.cat((x, images), 0)\n",
    "        idx = path.split(\"/\")[2] + \"_\"+ path.split(\"/\")[3]\n",
    "        y = torch.cat((y, torch.tensor(df[df[\"id\"] == idx]['peak_flux'].iloc[0]).reshape(-1,1)), 0)\n",
    "    return x, y\n",
    "\n",
    "for i, chunk in enumerate(chunks[:19]):\n",
    "    train_x, train_y = generateChunk(chunk)\n",
    "    dataset = TensorDataset(train_x, train_y)\n",
    "    torch.save(dataset, \"datachunks/chunk_{}.pt\".format(i))\n",
    "\n",
    "train_x, train_y = generateChunk(chunk)\n",
    "dataset = TensorDataset(train_x, train_y)\n",
    "torch.save(dataset, \"datachunks/chunk_{}.pt\".format(i))\n",
    "#train_x, train_y = generateChunk(chunks[5])\n",
    "#\n",
    "## Create a TensorDataset\n",
    "#dataset = TensorDataset(train_x, train_y)\n",
    "#\n",
    "## Create a DataLoader\n",
    "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "#\n",
    "#val_x, val_y = generateChunk(chunks[19])\n",
    "#\n",
    "## Create a TensorDataset\n",
    "#val_dataset = TensorDataset(val_x, val_y)\n",
    "#\n",
    "## Create a DataLoader\n",
    "#val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "685d339d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [04:00<00:00, 17.19s/it]\n",
      "100%|██████████| 14/14 [01:25<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8156483143220812, acc: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:59<05:58, 29.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, acc: \u001b[39m\u001b[39m{\u001b[39;00mtorch\u001b[39m.\u001b[39msum(outputs\u001b[39m \u001b[39m\u001b[39m==\u001b[39m\u001b[39m \u001b[39mtargets)\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39mlen\u001b[39m(targets)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m mod \u001b[39m=\u001b[39m SimpleCNN()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m train_model(mod, nn\u001b[39m.\u001b[39;49mMSELoss(), torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(mod\u001b[39m.\u001b[39;49mparameters()), dataloader, val_dataloader, \u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m mod \u001b[39m=\u001b[39m SimpleCNNWithWien()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train_model(mod, nn\u001b[39m.\u001b[39mMSELoss(), torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(mod\u001b[39m.\u001b[39mparameters()), dataloader, train_y, \u001b[39m10\u001b[39m)\n",
      "\u001b[1;32m/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb Cell 21\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)  \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs, targets\u001b[39m.\u001b[39mfloat())  \u001b[39m# Compute loss\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()  \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()  \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cameronbennett/Desktop/SDOBenchmark-data-full/SDOBenchmark.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39meval()  \u001b[39m# Set the model to evaluation mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NLP/lib/python3.11/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NLP/lib/python3.11/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            optimizer.zero_grad()  # Reset the gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, targets.float())  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # No need to track gradients in validation phase\n",
    "            for inputs, targets in tqdm(val_loader):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, acc: {torch.sum(outputs == targets) / len(targets)}')\n",
    "\n",
    "mod = SimpleCNN()\n",
    "train_model(mod, nn.MSELoss(), torch.optim.Adam(mod.parameters()), dataloader, val_dataloader, 10)\n",
    "mod = SimpleCNNWithWien()\n",
    "train_model(mod, nn.MSELoss(), torch.optim.Adam(mod.parameters()), dataloader, train_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
