{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c05422",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561b461-68c8-4779-a83f-eb1cb4520560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67de96-b138-41df-9fcd-3b60cc127536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"))) + \" Images for sample 1\")\n",
    "print(str(len(glob.glob(\"./training/*/*\"))) + \" Different Samples\")\n",
    "# Avg number of images per sample\n",
    "print(str(len(glob.glob(\"./training/*/*/*\"))/len(glob.glob(\"./training/*/*\"))) + \" Average number images per sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fec3f7-97c8-4d2f-addd-4ab18bd1416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for a single sample\n",
    "sample = []\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*\"):\n",
    "    print(i)\n",
    "    sample.append(Image.open(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89362f22-8024-4b72-905b-ab31e705f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_continuum.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad49a96-3df1-4a8e-ac90-158050fdf920",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_magnetogram.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67364843-2499-4858-9ddd-2931839f2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_211.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca01c0c-cf05-46ed-81ae-157774939034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _# represents AIA wavelength for band #\n",
    "# Hour Times: 05, 12, 15, 16\n",
    "# Not sure what continuum images represent\n",
    "for i in glob.glob(\"./training/11390/2012_01_05_17_06_01_0/*_304.jpg\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654af0e-8183-4087-9e7f-88e81e75e2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e767e5e-cf76-45fc-98e5-9661ebbcf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sample[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c509a15-d5f5-4293-81c1-d1e4085faaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"./training/11390/2012_01_05_17_06_01_0/2012-01-05T153601__magnetogram.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc65d-4e28-4e75-8245-fcbd36720f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.format)\n",
    "print(img.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e766d-c02a-4180-ab74-deb3930fbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8d027-3c19-4163-91ad-f298267a34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8E-07 is peak flux for this sample\n",
    "# Data Transformation 1: \n",
    "i = img.split()[0]\n",
    "len(i.histogram())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349bbea9",
   "metadata": {},
   "source": [
    "## Baseline network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad1415-ba73-4bd6-b2f7-db7242cbe986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layer (sees 256x256x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(in_channels=10, out_channels=16, kernel_size=3, padding=1)\n",
    "        # Convolutional layer (sees 128x128x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # Convolutional layer (sees 64x64x32 tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Linear layer (64 * 32 * 32 = 65536)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 512)\n",
    "        # Linear layer (512 -> 10)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        # Dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # Flatten image input\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the CNN\n",
    "model = SimpleCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4e96b",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "A single input will be a 4x256x256x10 matrix where dimensions represent: [timeinterval x height x width x wavelength/magnetogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314188a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Get a list of all active region numbers\n",
    "all_files = glob.glob(\"./training/*\")\n",
    "\n",
    "# Create a KFold object\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "wavelengths = [\"94\",\"131\", \"171\",\"193\",\"211\",\"304\",\"335\",\"1700\",\"continuum\",\"magnetogram\"]\n",
    "x = torch.zeros((1,4,256,256,10))\n",
    "y = torch.zeros((1,1))\n",
    "df = pd.read_csv('training/meta_data.csv')\n",
    "\n",
    "# Use the KFold object to split the data into 10 folds\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(all_files)):\n",
    "    train_files = np.array(all_files)[train_index]\n",
    "    val_files = np.array(all_files)[val_index]\n",
    "\n",
    "    # First we will loop over every active region number\n",
    "    for file in train_files:\n",
    "        for sample in glob.glob(file + \"/*\"):\n",
    "            images = torch.empty((4,256,256,1), dtype=torch.int64)\n",
    "            for wave in wavelengths:\n",
    "                path = sample + \"/*_{}.jpg\".format(wave)\n",
    "                pics = torch.tensor([np.array(Image.open(i)) for i in glob.glob(path)])\n",
    "                for _ in range(4 - len(pics)):\n",
    "                    pics = torch.cat((pics, torch.zeros((1, 256,256))), 0)\n",
    "                pics = pics.reshape(4,256,256,1)\n",
    "                images = torch.cat((images, pics), 3)\n",
    "            images = images[:,:,:,1:]\n",
    "            images = images.reshape(1,4,256,256,10)\n",
    "            x = torch.cat((x, images), 0)\n",
    "            idx = path.split(\"/\")[2] + \"_\"+ path.split(\"/\")[3]\n",
    "            y = torch.cat((y, torch.tensor(df[df[\"id\"] == idx]['peak_flux'].iloc[0]).reshape(-1,1)), 0)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76462e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
